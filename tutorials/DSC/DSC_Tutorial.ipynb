{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for AFMpy.REC.DSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# AFMpy imports\n",
    "from AFMpy import Stack, DL, Plotting, REC, SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each module in AFMpy contains logging to for debugging purposes via the default python logging library. Logging for the modules should always be configured at the application level. Included in these tutorials are example logging configuration files that can be loaded with the following functions. You may adjust these logging configuration files as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preconfigured logging settings\n",
    "with open('logs/DSC_Tutorial_LoggingConfig.json', 'r') as f:\n",
    "    LOGGING_CONFIG = json.load(f)\n",
    "\n",
    "# Set up the logging configuration\n",
    "logging.config.dictConfig(LOGGING_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included within the ```Plotting``` module are functions for creating the high quality figures. A default configuration that matches the figures in the publication is activated by running the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting.configure_formatting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the GPU is accessible by Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses Tensorflow and Keras in its deep learning algorithms. The performance, especially for large image stacks is substantially degraded when not using the GPU, so it is highly reccomended to use the GPU if available. The helper function ```DL.is_gpu_available``` will check to see if Tensorflow has GPU access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the GPU is available\n",
    "if DL.is_gpu_available():\n",
    "    print('GPU is accessible by tensorflow.')\n",
    "else:\n",
    "    print('GPU is NOT accessible by tensorflow. If you want to use GPU, please check your AFMpy version and tensorflow installation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the compressed pickle file of our aligned cytoplasmic/periplasmic stacks scanned with a 2nm tip at 4Å/px (AC-20-4 and AP-20-4 respectively). A comprehensive explanation of the loading functions is available in the ```LAFM``` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filepath for the public key to verify the integrity of the stacks.\n",
    "PUBLIC_KEY_FILEPATH = '../common/keys/Tutorial_Public.pub'\n",
    "\n",
    "# Load the cytoplasmic and periplasmic stacks\n",
    "cytoplasmic_stack = Stack.Stack.load_compressed_pickle(pickle_filepath = '../common/stacks/Example_AC-20-4.xz',\n",
    "                                                       public_key_filepath = PUBLIC_KEY_FILEPATH)\n",
    "\n",
    "periplasmic_stack = Stack.Stack.load_compressed_pickle(pickle_filepath = '../common/stacks/Example_AP-20-4.xz',\n",
    "                                                       public_key_filepath = PUBLIC_KEY_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the metadata of each stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Cytoplasmic stack metadata\n",
    "print('Cytoplasmic Stack Metadata:')\n",
    "cytoplasmic_stack.display_metadata()\n",
    "\n",
    "# Display the Periplasmic stack metadata\n",
    "print('Periplasmic Stack Metadata:')\n",
    "periplasmic_stack.display_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Convolutional Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the convolutional autoencoder (CAE) for deep spectral clustering.\n",
    "\n",
    "Distributed in ```AFMpy.Models``` is the abstract base class ```ConvolutionalAutoencoder```. This ABC is a template for custom convolutional autoencoders to inherit from. They must have the following attributes and abstract methods to be considered valid:\n",
    "\n",
    "- Attributes:\n",
    "    - ```Encoder``` (```keras.models.Model```): The encoder model that reduces an input image to a latent feature vector.\n",
    "    - ```Decoder``` (```keras.models.Model```): The decoder model that reconstructs an output image from a latent feature vector.\n",
    "    - ```Autoencoder``` (```keras.models.Model```): The combined model which concatenates ```Decoder``` onto ```Encoder```.\n",
    "- Abstract Methods:\n",
    "    - ```_build_models```: Method that sets the above model attributes.\n",
    "\n",
    "Additionally, the ```ConvolutionalAutoencoder``` class managed model compilation, training, and prediction settings through Python ```dataclasses```. The three compatible dataclasses are.\n",
    "\n",
    "- ```CompileConfig``` (```dataclass```): Compilation parameters\n",
    "    - ```optimizer``` (```tf.keras.optimizers.Optimizer```): The model optimizer. Default is ```'adam'```.\n",
    "    - ```loss``` (```tf.keras.losses.Loss```) The model loss. Default is ```DL.Losses.combined_ssim_loss```.\n",
    "    - ```compile_kwargs``` (```dict[str, Any]```): Additional keyword arguments for compiling the model.\n",
    "- ```FitConfig``` (```dataclass```): Fitting parameters\n",
    "    - ```epochs``` (```int```): Number of training epochs. Default is 25.\n",
    "    - ```batch_size``` (```int```): Number of samples to batch process before back propogation. Default is 32.\n",
    "    - ```verbose``` (```int```): Logging level. 0 for silent, 1 for progress bar, 2 for one line per epoch. Default is 1.\n",
    "    - ```callbacks``` (```List[tf.keras.callbacks.Callback]```) List of keras callbacks.\n",
    "    - ```fit_kwargs``` (```dict[str, Any]```): Additional keyword arguments for fitting the model.\n",
    "- ```PredictConfig``` (```dataclass```) Prediction parameters\n",
    "    - ```batch_size``` (```int```) Number of samples to batch process. Default is 32.\n",
    "    - ```verbose``` (```int```) Logging level. Same as ```FitConfig.verbose```.\n",
    "    - ```predict_kwargs``` (```dict[str,any]```) Additionally keyword arguments for predicting with the model.\n",
    "\n",
    "Included in AFMpy is an example ```ConvolutionalAutoencoder``` called ```DefaultCAE``` used for the analysis in our publication. To initialize an instance of the CAE, we pass the shape of an individual image (expanded to include a channel axis) to ```DL.DefaultCAE```. Hyperparameters such as the shape of convolutional filters (```filter_shape```), number of convolutional filters (```num_filters```), and the size of the latent feature vectors (```latent_dim```) can also be adjusted. Passing the config dataclasses as keyword arugments sets the compilation, fitting, and prediction configuration. If not specified, the defaults will be used.\n",
    "\n",
    "Here we create a separate CAE for the cytoplasmic and periplasmic stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the input shape for the CAE. It should be (width,height,channels). In our case (64,64,1)\n",
    "cyto_input_shape = (*cytoplasmic_stack.images.shape[1:], 1)\n",
    "peri_input_shape = (*periplasmic_stack.images.shape[1:], 1)\n",
    "\n",
    "# Set the configurations for the Convolutional Autoencoder. Adjust the parameters as needed.\n",
    "compile_config = DL.CompileConfig(optimizer = 'adam', loss = DL.Losses.combined_ssim_loss)\n",
    "fit_config = DL.FitConfig(epochs = 25, batch_size = 32, verbose = 1)\n",
    "predict_config = DL.PredictConfig(batch_size = 32, verbose = 1)\n",
    "\n",
    "# Create the Convolutional Autoencoder models to train with our data.\n",
    "cytoplasmic_CAE = DL.DefaultCAE(input_shape = cyto_input_shape, compile_config = compile_config, fit_config = fit_config, predict_config = predict_config)\n",
    "periplasmic_CAE = DL.DefaultCAE(input_shape = peri_input_shape, compile_config = compile_config, fit_config = fit_config, predict_config = predict_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained model weights are included in this tutorial to reduce computational load if necessary. It is important to note that pretrained weights will only funcion for the stack they are trained on. i.e. is is unlikely that a model trained on cytoplasmic images will be usable for periplasmic images, and vice versa. \n",
    "\n",
    "To load model weights from a file, use the ```ConvolutionalAutoencoder.load_weights``` method, which takes a single string/path argument. Likewise, after training a model, the ```ConvolutionalAutodencoder.save_weights``` method can be used to write the model weights to a file. Note: Weight files must always end with the suffix .weights.h5 or an exception will be raised.\n",
    "\n",
    "To use pretrained weights, adjust the following cell as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use pretrained weights or not.\n",
    "use_pretrained_weights = False\n",
    "\n",
    "# Load the pretrained weights if the user has set the flag to True.\n",
    "if use_pretrained_weights:\n",
    "    cytoplasmic_CAE.load_weights('../common/weights/Cytoplasmic_CAE.weights.h5')\n",
    "    periplasmic_CAE.load_weights('../common/weights/Periplasmic_CAE.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Deep Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cytoplasmic DSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model and Apply Deep Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the CAE now prepared, we can apply Deep Spectral Clustering (DSC). DSC is effective when the input stack is well aligned and the number of distinct conformations is known. If these conditions are not met, alternative methods such as Hierarchical DSC or IREC may be more appropriate (see the respective tutorials for details).\n",
    "\n",
    "The DSC algorithm follows the following steps:\n",
    "1. Latent Feature Extraction\n",
    "    - Images from the input stack are processed by the convolutional autoencoder to generate latent feature vectors. If the model is pretrained, (its ```trained``` attribute is ```True```), model fitting is skipped, and the pretrained model is evalulated only for feature extraction.\n",
    "2. Affinity Matrix Calculation\n",
    "    - The locally scaled affinity matrix is generated from the latent feature vectors.\n",
    "3. Spectral Clustering\n",
    "    - The affinity matrix is clustered by ```sklearn.cluster.SpectralClustering``` to generate ```n_clusters``` clusters.\n",
    "4. Clustered Stack Creation\n",
    "    - Images are grouped based upon the cluster labels and new ```Stack``` objects are created, one for each cluster. These clustered stacks are returned in a list.\n",
    "\n",
    "The parameters for calling ```REC.DSC``` are explained here:\n",
    "- ```input_stack``` (```Stack.Stack```): The stack of images to cluster.\n",
    "- ```cae``` (```Models.ConvolutionalAutoencoder```): The Convolutional Autoencoder to use for feature extraction.\n",
    "- ```n_clusters``` (```int``` default ```2```): Number of clusters to create.\n",
    "- ```k_neighbors``` (```int``` default ```7```): Local neighborhood for affinity scaling.\n",
    "- ```**kwargs```: Keyword arguments to pass to ```sklearn.cluster.SpectralClustering```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of clusters to calculate.\n",
    "n_cyto_clusters = 4\n",
    "\n",
    "# Use DSC to determine the cluster labels for the cytoplasmic stack  with n clusters\n",
    "cyto_clusters = REC.DSC(cytoplasmic_stack, cytoplasmic_CAE, n_clusters = n_cyto_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the LAFM Images for each cytoplamic cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the clusters now computed, we can calculate the Mean and LAFM images for each clustered stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the mean and LAFM images for each cluster.\n",
    "for cluster in cyto_clusters:\n",
    "    cluster.calc_mean_image()\n",
    "    cluster.calc_LAFM_image(target_resolution = (96,96), sigma = 2.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load And Process the Cytoplasmic Benchmark Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included alongside the AC-20-4 stack is an aligned cytoplasmic stack scanned with a 2Å tip scanning at 2Å/px (AC-2-2). Because of the small tip and high scanning resolution, we consider these stacks benchmark stacks.\n",
    "\n",
    "Here we load the benchmark stacks, and cluster them according to the cluster labels found by deep spectral clustering AC-20-4 creating equivalent benchmark clusters. Each benchmark cluster has it's LAFM image generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_cytoplasmic_stack = Stack.Stack.load_compressed_pickle(pickle_filepath = '../common/stacks/Example_AC-2-2.xz',\n",
    "                                                                 public_key_filepath = PUBLIC_KEY_FILEPATH)\n",
    "\n",
    "benchmark_cyto_clusters = []\n",
    "for cluster in cyto_clusters:\n",
    "    benchmark_images = benchmark_cytoplasmic_stack.images[cluster.indexes]\n",
    "    benchmark_cluster = Stack.Stack(images = benchmark_images, resolution = benchmark_cytoplasmic_stack.resolution, indexes = cluster.indexes)\n",
    "    benchmark_cluster.calc_LAFM_image(target_resolution = (192,192), sigma = 2.25)\n",
    "    benchmark_cyto_clusters.append(benchmark_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the Cytoplasmic Clustered LAFM Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now display the mean, LAFM, and benchmark LAFM images from each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color range based upon the maximum LAFM image value across all clusters.\n",
    "vmin = 0\n",
    "vmax = np.max([cluster.LAFM_image for cluster in cyto_clusters])\n",
    "\n",
    "# Create the figure.\n",
    "fig, ax = plt.subplots(n_cyto_clusters, 3, figsize = (9, 3 * n_cyto_clusters))\n",
    "\n",
    "# Turn off the tick marks\n",
    "for axis in ax.ravel():\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "\n",
    "# Set the axis labels \n",
    "ax[0,0].set_title('Mean Image', fontsize = 16)\n",
    "ax[0,1].set_title('LAFM Image', fontsize = 16)\n",
    "ax[0,2].set_title('Benchmark Image', fontsize = 16)\n",
    "\n",
    "# Plot the mean images, LAFM images, and benchmark images for each cluster.\n",
    "for i in range(n_cyto_clusters):\n",
    "    # Set the title for the cluster\n",
    "    ax[i,0].set_ylabel(f'Cluster {i}', fontsize = 16)\n",
    "\n",
    "    # Plot the mean image and its scalebar\n",
    "    cyto_clusters[i].plot_mean_image(ax = ax[i,0], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(10/cytoplasmic_stack.resolution, label = '1nm', ax = ax[i,0])\n",
    "\n",
    "    # Plot the LAFM image and its scalebar\n",
    "    cyto_clusters[i].plot_LAFM_image(ax = ax[i,1], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(30/cytoplasmic_stack.resolution, label = '1nm', size_vertical = 3/8, ax = ax[i,1])\n",
    "\n",
    "    # Plot the benchmark image and its scalebar\n",
    "    benchmark_cyto_clusters[i].plot_LAFM_image(ax = ax[i,2], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(60/cytoplasmic_stack.resolution, label = '1nm', size_vertical = 6/8, ax = ax[i,2])\n",
    "\n",
    "# Add the colorbars to the right of the images.\n",
    "cbar_ax = fig.add_axes([0.91, 0.11, 0.03, 0.77])\n",
    "Plotting.draw_colorbar_to_ax(vmin, vmax, Plotting.LAFMcmap,\n",
    "                             label = 'Height (Å)', cbar_ax = cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the SSIM between the LAFM images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the increase in image quality via LAFM by calculating the Structural Similarity Index Measure (SSIM) between the mean/LAFM image and the benchmark LAFM. \n",
    "\n",
    "We use a masked SSIM that omits background pixels during calculation. Call the function ```SSIM.masked_SSIM``` which takes two images with the same shape as input. A relative threshold ```threshold_rel``` detemrines the background. i.e. If a pixel's height is below ```thrshold_rel * max(img)``` in both images, it is ommitted from SSIM calculation. \n",
    "\n",
    "Below we calculate the SSIM values in a dataframe for displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_df = {\n",
    "    'Mean Image':[SSIM.masked_SSIM(cv2.resize(cyto_clusters[index].mean_image, (192,192), cv2.INTER_CUBIC), benchmark_cyto_clusters[index].LAFM_image) for index in range(len(cyto_clusters))],\n",
    "    'LAFM Image':[SSIM.masked_SSIM(cv2.resize(cyto_clusters[index].LAFM_image, (192,192), cv2.INTER_CUBIC), benchmark_cyto_clusters[index].LAFM_image) for index in range(len(cyto_clusters))]\n",
    "}\n",
    "ssim_df = pd.DataFrame(ssim_df)\n",
    "ssim_df.index = [f'Cluster {index}' for index in range(len(cyto_clusters))]\n",
    "display(ssim_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periplasmic Deep Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model and Apply Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we repeat the deep spectral clustering algorithm for the periplasmic stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of clusters to calculate.\n",
    "n_peri_clusters = 2\n",
    "\n",
    "# Use DSC to determine the cluster labels for the periplasmic stack  with n clusters\n",
    "peri_clusters = REC.DSC(periplasmic_stack, periplasmic_CAE, n_clusters = n_peri_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the LAFM Images for each periplamic cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the mean and LAFM images for each cluster.\n",
    "for cluster in peri_clusters:\n",
    "    cluster.calc_mean_image()\n",
    "    cluster.calc_LAFM_image(target_resolution = (96,96), sigma = 2.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Process the Periplasmic Benchmark Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_periplasmic_stack = Stack.Stack.load_compressed_pickle(pickle_filepath = '../common/stacks/Example_AP-2-2.xz',\n",
    "                                                                 public_key_filepath = PUBLIC_KEY_FILEPATH)\n",
    "\n",
    "benchmark_peri_clusters = []\n",
    "for cluster in peri_clusters:\n",
    "    benchmark_images = benchmark_periplasmic_stack.images[cluster.indexes]\n",
    "    benchmark_cluster = Stack.Stack(images = benchmark_images, resolution = benchmark_periplasmic_stack.resolution, indexes = cluster.indexes)\n",
    "    benchmark_cluster.calc_LAFM_image(target_resolution = (192,192), sigma = 2.25)\n",
    "    benchmark_peri_clusters.append(benchmark_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the periplasmic clustered LAFM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color range based on the maximum LAFM image value across all periplasmic clusters\n",
    "vmin = 0\n",
    "vmax = np.max([cluster.LAFM_image for cluster in peri_clusters])\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(n_peri_clusters, 3, figsize=(9, 3 * n_peri_clusters))\n",
    "\n",
    "# Turn off tick marks\n",
    "for axis in ax.ravel():\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "\n",
    "# Set axis labels\n",
    "ax[0, 0].set_title('Mean Image',      fontsize=16)\n",
    "ax[0, 1].set_title('LAFM Image',      fontsize=16)\n",
    "ax[0, 2].set_title('Benchmark Image', fontsize=16)\n",
    "\n",
    "for i in range(n_peri_clusters):\n",
    "    # Set the title for the cluster\n",
    "    ax[i,0].set_ylabel(f'Cluster {i}', fontsize = 16)\n",
    "\n",
    "    # Plot the mean image and its scalebar\n",
    "    peri_clusters[i].plot_mean_image(ax = ax[i,0], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(10/periplasmic_stack.resolution, label = '1nm', ax = ax[i,0])\n",
    "\n",
    "    # Plot the LAFM image and its scalebar\n",
    "    peri_clusters[i].plot_LAFM_image(ax = ax[i,1], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(30/periplasmic_stack.resolution, label = '1nm', size_vertical = 3/8, ax = ax[i,1])\n",
    "\n",
    "    # Plot the benchmark image and its scalebar\n",
    "    benchmark_peri_clusters[i].plot_LAFM_image(ax = ax[i,2], cmap = Plotting.LAFMcmap, vmin = vmin, vmax = vmax)\n",
    "    Plotting.add_scalebar(60/periplasmic_stack.resolution, label = '1nm', size_vertical = 6/8, ax = ax[i,2])\n",
    "\n",
    "# Add the colorbar\n",
    "cbar_ax = fig.add_axes([0.91, 0.11, 0.03, 0.77])\n",
    "Plotting.draw_colorbar_to_ax(vmin, vmax, Plotting.LAFMcmap,\n",
    "                             label='Height (Å)', cbar_ax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the SSIM between the LAFM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_df = {\n",
    "    'Mean Image':[SSIM.masked_SSIM(cv2.resize(peri_clusters[index].mean_image, (192,192), cv2.INTER_CUBIC), benchmark_peri_clusters[index].LAFM_image) for index in range(len(peri_clusters))],\n",
    "    'LAFM Image':[SSIM.masked_SSIM(cv2.resize(peri_clusters[index].LAFM_image, (192,192), cv2.INTER_CUBIC), benchmark_peri_clusters[index].LAFM_image) for index in range(len(peri_clusters))]\n",
    "}\n",
    "ssim_df = pd.DataFrame(ssim_df)\n",
    "ssim_df.index = [f'Cluster {index}' for index in range(len(peri_clusters))]\n",
    "\n",
    "display(ssim_df.round(2))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "AFMpy-GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
